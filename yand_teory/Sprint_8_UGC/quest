1. СI CD - уведомления  в ТГ работает?
2. СI CD - в тестах верно ли работает путь shared_dir куда записывается ответ файла, мне просто такой папеи нет
3. Как добавлять секреты в CI CD
4. Не совсем понял что описывает блок build в файле ugc_sprint_2_new/.github/workflows/ci.yml
А именно что делает вот этот участнок его нет в теории:
      - name: Lint with mypy
        run: |
          mypy ./benchmarks --ignore-missing-imports

5. В файле ugc_sprint_2_new/etl/db/kafka_streamer.py
в строке 37 из кафки читаются данные пользователя через срез строки - видимо так как там составной ключ юзер + фильм,
но где идет запись в кафку?

6. Зачем тут kafka_rw/kafka_writer.py 73 строка  применяется encode key=self.event_key.encode(),?
7. ДО какого момента выполняется эта функция в kafka_writer (ugc_sprint_2_new/kafka_rw/kafka_writer.py) - у меня она постоянно крутится и не останавливает?
while True:
    writer.run()
    sleep(config.writer.speed)

9. В файле ugc_sprint_2_new/etl/db/ch_storage.py  - в строке 24 на вход FilmBase в этом классе всего 2 поля и в нем нет поля progress_time
, такое поле появляется только в классе FilmView. Но видимо все равно все работает так как данные для записи в строку 24 попадают уже после чтения из кафки и там
есть поле value?

10.Как дать доступ к репо в ГХ(вопрос актуален если ты не видишь файлы из репо в пункте 11)?

11. Видиш ли ты это репо и эту ветку - она текущая
https://github.com/bigdatacon/https-github.com-bigdatacon-YAND_SPRINT_6_AUTH/tree/spr_8_1

12.Перенести данные из одного репо в другое
13. Сi/CD - особенно в части тестов, и секретов
14.Обговорить про докер - то есть он работает как отдельный компьютер и использует то ПО которыое в докерфайле прописано и не Важно
линукс на компе, винда или еще что?

17. Не запускат в докере кибану пишет нет доступа
18. Externak network в докере по логсташу
19. Откуда настройки для докера для filebeat?
20. Sentury настраивали или нет?
21.Докер файл не запускает ничего из папки ELK? То есть для чтения из кафки нет процесса?
22. ZOOKEPER запускается на одом порте для кликхаус и кафки?
23. Чтобы в кибане завести индекс нужно же сначала ее поднять, а если в докере кибана не запускается, получается индекс заранее создается при
поднятии кибаны отдельно? Но чтобы создать индекс требуется загрузить данные, если выбрать из вариантов логи - то они просят
установить filebeat - то есть все по новой начинается
https://disk.yandex.ru/i/3_yFXVyQ5NTttg


24. В докер компоузе путь для логов в докере для ETL прописан как /etl/log/
  etl:
    build: ./etl
    container_name: etl
    restart: always
    volumes:
      - ./log/etl/:/etl/log/

Но в filebeat прописан наоборот как путь до локальной системы      - /var/log/etl/*
или он и берет из локальной системы?

25. Докер бидится но не поднимается, ошибка в kafka_writer, но какая я понять не могут
